{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: `chartevents` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('../../')\n",
    "from tqdm import tqdm\n",
    "# from utils.icu_preprocess_util import *   \n",
    "from utils.labs_preprocess_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `chartevent` arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic4_path = \"./mimic-iv-1.0/\"\n",
    "usecols = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"stay_id\",\n",
    "    \"charttime\",\n",
    "    \"itemid\",\n",
    "    \"valuenum\",\n",
    "    \"valueuom\"\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    'itemid':'int64',\n",
    "    'subject_id':'int64',\n",
    "    'stay_id':'int64',\n",
    "    # 'hadm_id':'int64',            # hadm_id type not defined because it contains NaN values\n",
    "    # 'charttime':'datetime64[ns]', # used as an argument in 'parse_cols' in pd.read_csv\n",
    "    'valuenum':'float64',\n",
    "    'valueuom':'object',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit = pd.read_csv(mimic4_path + \"icu/icustays.csv.gz\", compression='gzip', header=0, index_col=None, parse_dates=['intime', 'outtime'])\n",
    "# pts = pd.read_csv(\n",
    "#             mimic4_path + \"core/patients.csv.gz\", compression='gzip', header=0, index_col = None, usecols=['subject_id', 'anchor_year', 'anchor_age', 'anchor_year_group', 'dod','gender']\n",
    "#         )\n",
    "# pts['yob']= pts['anchor_year'] - pts['anchor_age']  # get yob to ensure a given visit is from an adult\n",
    "# pts['min_valid_year'] = pts['anchor_year'] + (2019 - pts['anchor_year_group'].str.slice(start=-4).astype(int))\n",
    "# # only take adult patients\n",
    "# visit_pts['Age']=visit_pts['intime'].dt.year - visit_pts['yob']\n",
    "# visit_pts = visit_pts.loc[visit_pts['Age'] >= 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define modified `preproc_chart` to read in `chartevents` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_chart(dataset_path: str, cohort_path:str, time_col:str, dtypes: dict, usecols: list) -> pd.DataFrame:\n",
    "    \"\"\"Function for getting hosp observations pertaining to a pickled cohort. Function is structured to save memory when reading and transforming data.\"\"\"\n",
    "    \n",
    "    # Only consider values in our cohort\n",
    "    cohort = pd.read_csv(cohort_path, compression='gzip', parse_dates = ['intime'])\n",
    "    df_cohort=pd.DataFrame()\n",
    "        # read module w/ custom params\n",
    "    chunksize = 5000000\n",
    "    for chunk in tqdm(pd.read_csv(dataset_path, compression='gzip', usecols=usecols, dtype=dtypes, parse_dates=[time_col],chunksize=chunksize)):\n",
    "        #print(chunk.head())\n",
    "        # chunk['valuenum']=chunk['valuenum'].fillna(0) # <<< commented out this line\n",
    "        chunk_merged=chunk.merge(cohort[['stay_id', 'intime']], how='inner', left_on='stay_id', right_on='stay_id')\n",
    "        chunk_merged['event_time_from_admit'] = chunk_merged[time_col] - chunk_merged['intime']\n",
    "        \n",
    "        del chunk_merged[time_col] \n",
    "        del chunk_merged['intime']\n",
    "        chunk_merged=chunk_merged.dropna(subset=['itemid', 'valuenum', 'valueuom']) # <<< edited line\n",
    "        chunk_merged=chunk_merged.drop_duplicates()\n",
    "        \n",
    "        if df_cohort.empty:\n",
    "            df_cohort=chunk_merged\n",
    "        else:\n",
    "            df_cohort=df_cohort.append(chunk_merged, ignore_index=True)\n",
    "\n",
    "    # Print unique counts and value_counts\n",
    "    print(\"# Unique Events:  \", df_cohort.itemid.dropna().nunique())\n",
    "    print(\"# Admissions:  \", df_cohort.stay_id.nunique())\n",
    "    print(\"Total rows\", df_cohort.shape[0])\n",
    "\n",
    "    # Only return module measurements within the observation range, sorted by subject_id\n",
    "    return df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [08:10,  9.09s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.05 GiB for an array with shape (1, 275000000) and data type timedelta64[ns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ee9ed3fbb7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get chartevents data for our cohort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcharts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreproc_chart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmimic4_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"icu/chartevents.csv.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmimic4_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"icu/icustays.csv.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"charttime\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-60b8622e6535>\u001b[0m in \u001b[0;36mpreproc_chart\u001b[1;34m(dataset_path, cohort_path, time_col, dtypes, usecols)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mdf_cohort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_merged\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdf_cohort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_cohort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_merged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Print unique counts and value_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7980\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7981\u001b[0m         return (\n\u001b[1;32m-> 7982\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   7983\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7984\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[0;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_contains_datetime\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"timedelta\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtyps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_concat_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mall_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36m_concat_datetime\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_same_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_concat_same_type\u001b[1;34m(cls, to_concat, axis)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     ) -> DatetimeLikeArrayT:\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[0mnew_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_same_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py\u001b[0m in \u001b[0;36m_concat_same_type\u001b[1;34m(cls, to_concat, axis)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_backing_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.05 GiB for an array with shape (1, 275000000) and data type timedelta64[ns]"
     ]
    }
   ],
   "source": [
    "# get chartevents data for our cohort\n",
    "charts = preproc_chart(mimic4_path + \"icu/chartevents.csv.gz\", mimic4_path + \"icu/icustays.csv.gz\", \"charttime\", dtypes, usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>event_time_from_admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003700</td>\n",
       "      <td>28623837</td>\n",
       "      <td>30600691</td>\n",
       "      <td>220179</td>\n",
       "      <td>152.0</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>-1 days +23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003700</td>\n",
       "      <td>28623837</td>\n",
       "      <td>30600691</td>\n",
       "      <td>220180</td>\n",
       "      <td>97.0</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>-1 days +23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003700</td>\n",
       "      <td>28623837</td>\n",
       "      <td>30600691</td>\n",
       "      <td>220181</td>\n",
       "      <td>110.0</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>-1 days +23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003700</td>\n",
       "      <td>28623837</td>\n",
       "      <td>30600691</td>\n",
       "      <td>220045</td>\n",
       "      <td>65.0</td>\n",
       "      <td>bpm</td>\n",
       "      <td>-1 days +23:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003700</td>\n",
       "      <td>28623837</td>\n",
       "      <td>30600691</td>\n",
       "      <td>220210</td>\n",
       "      <td>14.0</td>\n",
       "      <td>insp/min</td>\n",
       "      <td>-1 days +23:47:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   stay_id  itemid  valuenum  valueuom  \\\n",
       "0    10003700  28623837  30600691  220179     152.0      mmHg   \n",
       "1    10003700  28623837  30600691  220180      97.0      mmHg   \n",
       "2    10003700  28623837  30600691  220181     110.0      mmHg   \n",
       "3    10003700  28623837  30600691  220045      65.0       bpm   \n",
       "4    10003700  28623837  30600691  220210      14.0  insp/min   \n",
       "\n",
       "  event_time_from_admit  \n",
       "0     -1 days +23:45:00  \n",
       "1     -1 days +23:45:00  \n",
       "2     -1 days +23:45:00  \n",
       "3     -1 days +23:47:00  \n",
       "4     -1 days +23:47:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rows in itemid: 0\n",
      "NaN rows in valuenum: 0\n",
      "NaN rows in valueuom: 0\n",
      "(81030530, 7)\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values for itemid, valuenum, and valueuom\n",
    "for col in ['itemid', 'valuenum', 'valueuom']:\n",
    "    print(f\"NaN rows in {col}:\", charts['itemid'].loc[charts['itemid'].isna()].shape[0])\n",
    "    \n",
    "charts.dropna(subset=['itemid', 'valuenum', 'valueuom'], inplace=True)\n",
    "print(charts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[227441, 229357, 229358, 229360]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non standard itemids; have more than 1 unit of measure\n",
    "nonstd_itemids = list(charts[['itemid', 'valueuom']].dropna().drop_duplicates().groupby(by='itemid').size().loc[charts[['itemid', 'valueuom']].dropna().drop_duplicates().groupby(by='itemid').size() > 1].index)\n",
    "nonstd_itemids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chartevents size before filtering for majority uom (81030530, 7)\n",
      "chartevents size after filtering for majority uom (80961394, 7)\n"
     ]
    }
   ],
   "source": [
    "charts_preproc = charts.copy()\n",
    "print(\"chartevents size before filtering for majority uom\", charts_preproc.shape)\n",
    "for i in nonstd_itemids:\n",
    "    try:\n",
    "        maj = charts_preproc.loc[charts_preproc.itemid == i].valueuom.value_counts().index[0]\n",
    "        charts_preproc = charts_preproc.loc[~((charts_preproc.itemid == i) & (charts_preproc.valueuom == maj))]\n",
    "    except IndexError:\n",
    "        print(f\"{idx} not found\")\n",
    "\n",
    "print(\"chartevents size after filtering for majority uom\", charts_preproc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39d0725753d0ad0b2b78de10b3b7451c8aa9b3c904c7c1796a98e42af75eb3a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
